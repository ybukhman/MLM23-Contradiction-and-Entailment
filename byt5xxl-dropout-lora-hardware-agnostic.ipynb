{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30581,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1) Getting Setup","metadata":{}},{"cell_type":"code","source":"!pip install wandb\n!pip install jupyter --upgrade\n!pip install ipywidgets widgetsnbextension --upgrade\n# !pip install nlpaug\n# !pip install sacremoses","metadata":{"execution":{"iopub.status.busy":"2023-11-16T01:35:50.849073Z","iopub.execute_input":"2023-11-16T01:35:50.849917Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.12)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.34.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nCollecting jupyter\n  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nRequirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.5.5)\nRequirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter) (5.5.0)\nRequirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.6.3)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.4.5)\nRequirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.25.1)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from jupyter) (7.7.1)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.4)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.7.post1)\nRequirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (8.14.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.3.1)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (1.5.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.9.3)\nRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (6.3.3)\nRequirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.9.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (0.2.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.6.6)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.0.8)\nRequirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter) (3.0.39)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter) (2.16.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (3.1.2)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.2.2)\nRequirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (5.9.2)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (2.1.3)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (21.3.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (0.17.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (0.17.1)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (1.0.0)\nRequirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter) (2.4.1)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.11.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (2.9.1)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter) (2.18.0)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.19.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.6)\nRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.2.post1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel->jupyter) (3.0.9)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (23.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (0.9.2)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\nRequirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.7.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.4.4)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (6.5.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.6.2)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.1.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (6.0.1)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (2.0)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.2.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nimport transformers\nimport torch\nimport glob\nimport pandas as pd\nfrom tqdm import tqdm\nimport numpy as np\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig\nfrom torch import nn\nimport sys\nimport gc\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AdamW\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom accelerate import notebook_launcher\nfrom accelerate import DistributedDataParallelKwargs\n# from torch.distributed.fsdp import (\n#    FullyShardedDataParallel,\n# )\n# import nlpaug.augmenter.word as naw","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\ndef seed_everything(seed: int):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dict_from_class(cls):\n    return dict((key, value) for (key, value) in cls.__dict__.items() if not \"__\" in key )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    # General Configuration\n    seed = 42\n    base_path = \"/kaggle/input/contradictory-my-dear-watson\"\n    mode = \"maximize\"\n    patience = 8\n    device_type = \"gpus\"\n    \n    # WandB Configuration\n    name = \"Baseline\"\n    model_name = \"google/byt5-large\"\n    metric_name = \"accuracy\"\n\n    # Training Configuration\n        # EDA shows no sentence longer than 196 words!\n        \n    lr = 2e-5\n    epochs = 40\n    patience = 8\n    grad_accum = 8\n    optimizer = \"AdamW\"\n    scheduler = \"cosine\"\n    batch_size = 4\n    warmup_pct = 0.1\n    weight_decay = 0.0\n    \n    # Data Configuration\n#     max_length = \"longest_first\"\n    truncation = True\n    padding = True\n    test_size = 0.2\n    back_translate = 0.5\n    dropout = 0.3\n    upsample = True\n    \n    # LoRA hyperparameters\n    r = 8\n    lora_alpha = 8\n    lora_dropout = 0.1\n    bias = \"all\"\n        \nconfig.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\nconfig.checkpoint = f\"/kaggle/working/{config.model_name}.pt\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.device_type == \"gpu\":\n    config.batch_size = 4\nelif config.device_type == \"gpus\":\n    # Batch of 8 for each gpu\n    config.batch_size = 4\nelif config.device_type == \"tpu\":\n    # Batch of 128 for each TPU core\n    config.batch_size = 128","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Signing into WandB\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\n!wandb login $secret_value_0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1) Trackers","metadata":{}},{"cell_type":"code","source":"class LossTracker:\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AccuracyTracker():\n    def __init__(self):\n        self.correct_predictions = 0.0\n        self.total_predictions = 0.0\n        \n    def update(self, y_hat, y):\n        preds = y_hat.detach().cpu().numpy()\n        labels = y.detach().cpu().numpy()\n        \n        n = len(preds)\n        self.correct_predictions += (preds == labels).sum()        \n        self.total_predictions += n\n    \n    def score(self):\n        return self.correct_predictions / self.total_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ModelTracker():\n    def __init__(self, model, optimizer, scheduler, accelerator):\n        self.missed = 0\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.metric = float(\"-inf\") if config.mode == \"maximize\" else float(\"inf\")\n        self.accelerator = accelerator\n        \n    def save_helper(self, epoch):\n        self.accelerator.save({\n                    \"epoch\": epoch, \n                    \"model_state_dict\": self.accelerator.unwrap_model(self.model).state_dict(), \n                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n                    \"scheduler\": self.scheduler.state_dict()\n                }, config.checkpoint)\n\n        self.accelerator.print(f\"Saved to model to {config.checkpoint}!\")\n        \n    def save_model(self, epoch):\n        self.save_helper(epoch)\n        \n\n    def update(self, value, epoch):\n        if config.mode == \"maximize\":\n            if value >= self.metric:\n                self.accelerator.print(f\"Validation {config.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.metric = value\n                self.save_model(epoch)    \n                self.missed = 0\n\n            else:\n                self.accelerator.print(f\"Validation {config.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.accelerator.print(f\"Model did not improve on epoch {epoch}\")\n                self.missed += 1\n        else:\n            if value <= self.metric:\n                self.accelerator.print(f\"Validation {config.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.metric = value\n                self.save_model(epoch) \n                self.missed = 0\n\n            else:\n                self.accelerator.print(f\"Validation {config.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.accelerator.print(f\"Model did not improve on epoch {epoch}\")\n                self.missed += 1\n        \n    def check_improvement(self):\n        return self.missed < config.patience","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Data Loading","metadata":{}},{"cell_type":"markdown","source":"# 2.2) Data Loading","metadata":{}},{"cell_type":"code","source":"class TrainData(Dataset):\n    def __init__(self, df):\n        self.df = df\n#         self.en_to_chinese = AutoModel.from_pretrained('Helsinki-NLP/opus-mt-en-zh')\n#         self.en_to_arabic = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n#         self.en_to_french = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n#         self.en_to_swah = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-sw\")\n#         self.en_to_urdu = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ur\")\n#         self.en_to_viet = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-vi\")\n#         self.en_to_russ = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")\n#         self.en_to_hindi = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n#         self.en_to_thai = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-th\")\n#         self.en_to_greek = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-gr\")\n#         self.en_to_spanish = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-sp\")\n# #         self.en_to_german = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-gr\")\n#         self.en_to_turkish = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-tr\")\n#         self.en_to_bulgarian = AutoModel.from_pretrained(\"Helsinki-NLP/opus-mt-en\") \n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        selection = self.df.iloc[index]\n        \n        premise = selection[\"premise\"]\n        \n        hypothesis = selection[\"hypothesis\"]\n        \n        language = selection[\"language\"]\n        \n#         if language == \"English\":\n#             if np.random.uniform() >= config.back_translate:\n#                 premise = self.aug.augment(selection[\"premise\"], num_thread = 0)\n            \n#             if np.random.uniform() >= config.back_translate:\n\n#                 hypothesis = self.aug.augment(selection[\"hypothesis\"], num_thread = 0)\n        \n        \n        return premise, hypothesis, selection[\"label\"]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestData(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        selection = self.df.iloc[index]\n        return selection[\"premise\"], selection[\"hypothesis\"], selection[\"label\"], selection[\"language\"]\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_collate_dynamic_padding(batch):\n    batch = np.array(batch, dtype = \"object\")\n    text_input = batch[:, 0:2].tolist()\n    labels = batch[:, 2].astype(int)\n    \n    tokens = config.tokenizer(text_input, padding=config.padding, truncation = config.truncation, return_tensors=\"pt\")\n    return tokens, torch.tensor(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_collate_dynamic_padding(batch):\n    batch = np.array(batch, dtype = \"object\")\n    text_input = batch[:, 0:2].tolist()\n    labels = batch[:, 2].astype(int)\n    languages = batch[:, 3]\n    \n    tokens = config.tokenizer(text_input, padding=config.padding, truncation = config.truncation, return_tensors=\"pt\")\n    return tokens, torch.tensor(labels), languages","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3) Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, train_len):\n        super(Model, self).__init__()\n        self.train_len = train_len\n        self.base_model = AutoModel.from_pretrained(config.model_name).encoder\n        self.dropout = nn.Dropout(p = config.dropout)\n        self.fc = nn.Linear(self.base_model.config.hidden_size, 3)\n        \n    def feature(self, inputs):\n        x = self.base_model(**inputs)[\"last_hidden_state\"]\n        return x[:, 0, :]\n    \n    def forward(self, inputs):\n        features = self.feature(inputs)\n        \n        return self.fc(self.dropout(features))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4) Training Loop","metadata":{}},{"cell_type":"markdown","source":"## 4.1) Data Preparation","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{config.base_path}/train.csv\")\ntrain, test = train_test_split(train, test_size = config.test_size, stratify = train[\"lang_abv\"], random_state = config.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2) Criterions + Optimizers + Schedulers","metadata":{}},{"cell_type":"code","source":"def generateConfusionMatrices(val_preds):\n    for lang in val_preds.langs.unique():\n        filtered_df = val_preds.loc[val_preds.langs == lang]\n        y = list(filtered_df.y.astype(int))\n        y_hat = list(filtered_df.y_hat.astype(int))\n        \n        wandb.log({f\"{lang} Confusion Matrix\": wandb.plot.confusion_matrix(y_true=y, preds=y_hat, class_names=[\"entailment\", \"contradiction\", \"neutral\"], title = f\"{lang} Confusion Matrix\", )})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, accelerator):\n    model.train()\n    model.to(config.device)\n    \n    loss_tracker = LossTracker()\n    accuracy_tracker = AccuracyTracker()\n\n    progress_bar = tqdm(train_loader, desc = f\"Training Loop Epoch: {epoch}\")\n    \n    average_acc = None\n    \n    for batch_idx, batch in enumerate(progress_bar):\n        with accelerator.accumulate(model):\n            inputs, labels = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(config.device)\n\n            labels = labels.to(config.device)\n            batch_size = labels.size(0)\n\n            logits = model(inputs)\n            # PyTorch CrossEntropy uses the unnormalized logits\n            train_loss = criterion(logits, labels)\n            scaled_loss = train_loss / config.grad_accum\n\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n\n            accuracy_tracker.update(y_hat, labels)\n\n            loss_tracker.update(train_loss.item(), batch_size)\n\n            accelerator.backward(scaled_loss)\n\n            if ((batch_idx + 1) % config.grad_accum == 0) or (batch_idx + 1 == model.train_len):\n\n                optimizer.step()\n\n                optimizer.zero_grad()\n\n                if not scheduler is None:\n                    scheduler.step()\n                    for i, lr in enumerate(scheduler.get_last_lr()):\n                        accelerator.log({f\"Layer {i} Learning Rate\": lr})\n                        \n            avg_accuracy = accuracy_tracker.score()\n            avg_loss = loss_tracker.avg\n            step_loss = loss_tracker.val\n            learning_rate = scheduler.get_last_lr()[0]\n\n            text = f\"Epoch: {epoch} | Average Training Accuracy: {avg_accuracy:.4f} | Average Training Loss: {avg_loss:.4f} | Step Training Loss: {step_loss:.4f} | Learning Rate: {learning_rate:.4f}\"\n            progress_bar.set_postfix_str(text)\n            progress_bar.refresh()\n\n            accelerator.log({f\"Step Training Loss\": step_loss})\n\n    epoch_loss = loss_tracker.avg\n    epoch_accuracy = accuracy_tracker.score()\n\n    accelerator.log({f\"Training Loss Epoch\": epoch_loss})\n    accelerator.log({f\"Training Accuracy Epoch\": epoch_accuracy})\n    accelerator.print(f\"Training Loss: {epoch_loss} | Training Accuracy: {epoch_accuracy}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_fn(val_loader, model, criterion, epoch, accelerator):\n    with torch.no_grad():\n        model.eval()\n        model.to(config.device)\n\n        loss_tracker = LossTracker()\n        accuracy_tracker = AccuracyTracker()\n\n        progress_bar = tqdm(val_loader, desc = f\"Validation Loop Epoch: {epoch}\")\n\n        for batch_idx, batch in enumerate(progress_bar):\n\n            inputs, labels = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(config.device)\n\n            labels = labels.to(config.device)\n            batch_size = labels.size(0)\n\n            logits = accelerator.unwrap_model(model)(inputs)\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n\n            val_loss = criterion(logits, labels)\n\n            accuracy_tracker.update(y_hat, labels)\n            loss_tracker.update(val_loss.item(), batch_size)\n\n            avg_val_loss = loss_tracker.avg\n            avg_val_acc = accuracy_tracker.score()\n\n            progress_bar.set_postfix_str(f\"Epoch: {epoch} | Average Validation Accuracy {avg_val_acc:.4f}| Average Validation Loss: {avg_val_loss:.4f}\")\n            progress_bar.refresh()\n\n\n        epoch_loss = loss_tracker.avg\n        epoch_accuracy = accuracy_tracker.score()\n\n        accelerator.log({f\"Validation Loss Epoch\": epoch_loss})\n        accelerator.log({f\"Validation Accuracy Epoch\": epoch_accuracy})\n        accelerator.print(f\"Validation Loss: {epoch_loss} | Validation Accuracy: {epoch_accuracy}\")\n    \n    return epoch_accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_fn(test_loader, model, checkpoint, accelerator):\n    with torch.no_grad():\n        model.to(accelerator.device)\n        model.eval()\n\n        accuracy_tracker = AccuracyTracker()\n\n        preds = []\n        actual = []\n        langs = []\n\n        progress_bar = tqdm(test_loader, desc = f\"Test Loop\")\n        for batch_idx, batch in enumerate(progress_bar):\n\n            inputs, labels, languages = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(accelerator.device)\n\n            labels = labels.to(acclerator.device)\n            batch_size = labels.size(0)\n\n            logits = model(inputs)\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n            accuracy_tracker.update(y_hat, labels)\n\n            preds.extend(y_hat.detach().cpu().numpy())\n            actual.extend(labels.detach().cpu().numpy())\n            langs.extend(languages)\n\n\n            avg_val_acc = accuracy_tracker.score()\n\n            progress_bar.set_postfix_str(f\"Average Test Accuracy {avg_val_acc}\")\n            progress_bar.refresh()\n\n        test_accuracy = accuracy_tracker.score()\n\n        wandb.log({f\"Final Test Accuracy\": test_accuracy})\n        accelerator.print(f\"Test Accuracy: {test_accuracy}\")\n\n        test_preds = pd.DataFrame(np.array([preds, actual, langs]).T, columns = [\"y_hat\", \"y\", \"langs\"])\n        test_preds.to_csv(\"Test Predictions.csv\")\n        \n        # I need to run this because accelerator's API doesn't expose anything to directly save a csv.\n        wandb.save(f\"/kaggle/working/Test Predictions.csv\")\n        accelerator.print(\"Saved Test Predictions to /kaggle/working/Test Predictions.csv\")\n\n        generateConfusionMatrices(test_preds)\n\n        return test_accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation Data and Test Data are both the same in this case!\n# They are distinguished for logging purposes!\ntrain_data, val_data, test_data = TrainData(train), TrainData(test), TestData(test)\n\n# Getting sample weights for balancing data\nweights = (1 / train.language.value_counts()).to_dict()\ntrain[\"weight\"] = train.apply(lambda row: weights[row.language], axis = 1)\nsample_weights = list(train[\"weight\"])\n\ntrain_sampler = WeightedRandomSampler(sample_weights, len(train_data))\n\ntrain_data_loader = DataLoader(train_data, collate_fn = train_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count(), sampler = train_sampler)\n\n\nval_data_loader = DataLoader(test_data, collate_fn = train_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count())\ntest_data_loader = DataLoader(test_data, collate_fn = test_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = torch.compile(Model(len(train_data_loader)))\n# model = FullyShardedDataParallel(Model(len(train_data_loader)))\nmodel = Model(len(train_data_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig(r = config.r, bias = config.bias, lora_dropout = config.lora_dropout, target_modules=[\"q\", \"k\", \"v\", \"o\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(model):\n    seed_everything(config.seed)\n    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n    if config.device_type == \"cuda\" or config.device_type == \"gpus\":\n        accelerator = Accelerator(mixed_precision = \"fp16\", gradient_accumulation_steps = config.grad_accum, log_with = \"wandb\", kwargs_handlers=[ddp_kwargs])\n        config.device = accelerator.device\n    elif config.device_type == \"tpu\":\n        accelerator = Accelerator(mixed_precision = \"bf16\", gradient_accumulation_steps = config.grad_accum, downcast_bf16=True, log_with = \"wandb\", kwargs_handlers=[ddp_kwargs])\n        config.device = accelerator.device\n\n    accelerator.init_trackers(\n        \"My Dear Watson\",\n        config=dict_from_class(config),\n        init_kwargs={\n            \"wandb\": {\n                \"group\": config.name,\n                \"reinit\": False,\n                \"job_type\": config.model_name,\n                \"name\": f\"Seed {config.seed}\",\n                \"entity\": \"uw-kaggle\",\n            }\n        },\n    )\n    ######################################################################\n    criterion = nn.CrossEntropyLoss()\n    optimizer = AdamW(model.parameters(), weight_decay = config.weight_decay, lr = config.lr, correct_bias = True)\n\n    warmup_steps = model.train_len * config.warmup_pct\n    num_training_steps = model.train_len * config.epochs // config.grad_accum\n\n    scheduler = transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps, num_training_steps = num_training_steps)\n    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(model, optimizer, train_data_loader, val_data_loader, scheduler)\n    ######################################################################\n    tracker = ModelTracker(model, optimizer, scheduler, accelerator)\n    \n    for epoch in range(config.epochs):\n\n        train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, accelerator)\n\n        val_accuracy = valid_fn(val_loader, model, criterion, epoch, accelerator)\n\n        accelerator.wait_for_everyone()\n        tracker.update(val_accuracy, epoch)\n\n        if not tracker.check_improvement():\n            print(f\"Stopping the model at epoch {epoch} since the model did not improve!\")\n            break\n    \n    accelerator.wait_for_everyone()\n\n    gc.collect()\n\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.device_type == \"tpu\":\n    # Ignore print message that says it's running on 8 GPUs\n    notebook_launcher(train_loop, (model,), num_processes = 8)\n    \nelif config.device_type == \"gpus\":\n    notebook_launcher(train_loop, (model,), num_processes = torch.cuda.device_count())\n    \nelse:\n    train_loop(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Getting Test Predictions","metadata":{}},{"cell_type":"code","source":"acclerator = Accelerator(log_with = \"wandb\")\naccelerator.init_trackers(\n        \"My Dear Watson\",\n        config=dict_from_class(config),\n        init_kwargs={\n            \"wandb\": {\n                \"group\": config.name,\n                \"reinit\": False,\n                \"resume\": True,\n                \"job_type\": config.model_name,\n                \"name\": f\"Seed {config.seed}\",\n                \"entity\": \"uw-kaggle\",\n            }\n        },\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved = torch.load(config.checkpoint)\nmodel = accelerator.unwrap_model(model)\nmodel.load_state_dict(saved[\"model_state_dict\"])\nmodel = torch.compile(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, test_loader = accelerator.prepare(model, test_data_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fn(test_loader, model, config.checkpoint, accelerator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accelerator.end_training()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}