{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"},{"sourceId":7086302,"sourceType":"datasetVersion","datasetId":4082864}],"dockerImageVersionId":30581,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1) Getting Setup","metadata":{}},{"cell_type":"code","source":"!pip install wandb\n!pip install jupyter --upgrade\n!pip install ipywidgets widgetsnbextension --upgrade\n!pip install -q peft","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:47.135819Z","iopub.execute_input":"2023-11-30T23:11:47.136666Z","iopub.status.idle":"2023-11-30T23:12:36.475717Z","shell.execute_reply.started":"2023-11-30T23:11:47.136630Z","shell.execute_reply":"2023-11-30T23:12:36.474535Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.12)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.34.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nCollecting jupyter\n  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\nRequirement already satisfied: notebook in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.5.5)\nRequirement already satisfied: qtconsole in /opt/conda/lib/python3.10/site-packages (from jupyter) (5.5.0)\nRequirement already satisfied: jupyter-console in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.6.3)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.4.5)\nRequirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from jupyter) (6.25.1)\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (from jupyter) (7.7.1)\nRequirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.4)\nRequirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (1.6.7.post1)\nRequirement already satisfied: ipython>=7.23.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (8.14.0)\nRequirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (7.4.9)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.3.1)\nRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (0.1.6)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (1.5.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.9.3)\nRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (24.0.1)\nRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (6.3.3)\nRequirement already satisfied: traitlets>=5.4.0 in /opt/conda/lib/python3.10/site-packages (from ipykernel->jupyter) (5.9.0)\nRequirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (0.2.0)\nRequirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.6.6)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets->jupyter) (3.0.8)\nRequirement already satisfied: prompt-toolkit>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter) (3.0.39)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from jupyter-console->jupyter) (2.16.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.8.4)\nRequirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (3.1.2)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.2.2)\nRequirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (5.9.2)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.4)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (6.0.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.0)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.6.0)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (4.12.2)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (0.5.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert->jupyter) (2.1.3)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (21.3.0)\nRequirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (1.8.2)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (0.17.1)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (0.17.1)\nRequirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook->jupyter) (1.0.0)\nRequirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from qtconsole->jupyter) (2.4.1)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\nRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.11.0)\nRequirement already satisfied: jupyter-server>=1.8 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (2.9.1)\nRequirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\nRequirement already satisfied: fastjsonschema in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter) (2.18.0)\nRequirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.10/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.19.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.6)\nRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\nRequirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.2.post1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ipykernel->jupyter) (3.0.9)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (23.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (0.9.2)\nRequirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.7.1)\nRequirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.7.0)\nRequirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.4.4)\nRequirement already satisfied: overrides in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (6.5.0)\nRequirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.6.2)\nRequirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.1.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\nRequirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (2.0.7)\nRequirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (6.0.1)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.4)\nRequirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.1)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.5.1)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (2.0)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.3.0)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter) (1.2.3)\nInstalling collected packages: jupyter\nSuccessfully installed jupyter-1.0.0\nRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.10/site-packages (7.7.1)\nCollecting ipywidgets\n  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/4a/0e/57ed498fafbc60419a9332d872e929879ceba2d73cb11d284d7112472b3e/ipywidgets-8.1.1-py3-none-any.whl.metadata\n  Downloading ipywidgets-8.1.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: widgetsnbextension in /opt/conda/lib/python3.10/site-packages (3.6.6)\nCollecting widgetsnbextension\n  Obtaining dependency information for widgetsnbextension from https://files.pythonhosted.org/packages/29/03/107d96077c4befed191f7ad1a12c7b52a8f9d2778a5836d59f9855c105f6/widgetsnbextension-4.0.9-py3-none-any.whl.metadata\n  Downloading widgetsnbextension-4.0.9-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\nRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (8.14.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets) (5.9.0)\nCollecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n  Obtaining dependency information for jupyterlab-widgets~=3.0.9 from https://files.pythonhosted.org/packages/e8/05/0ebab152288693b5ec7b339aab857362947031143b282853b4c2dd4b5b40/jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata\n  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\nDownloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.9/214.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n  Attempting uninstall: widgetsnbextension\n    Found existing installation: widgetsnbextension 3.6.6\n    Uninstalling widgetsnbextension-3.6.6:\n      Successfully uninstalled widgetsnbextension-3.6.6\n  Attempting uninstall: jupyterlab-widgets\n    Found existing installation: jupyterlab-widgets 3.0.8\n    Uninstalling jupyterlab-widgets-3.0.8:\n      Successfully uninstalled jupyterlab-widgets-3.0.8\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 7.7.1\n    Uninstalling ipywidgets-7.7.1:\n      Successfully uninstalled ipywidgets-7.7.1\nSuccessfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\n","output_type":"stream"}]},{"cell_type":"code","source":"from accelerate import Accelerator\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport wandb\nimport transformers\nimport torch\nimport glob\nimport pandas as pd\nfrom tqdm import tqdm\nimport numpy as np\nimport os\nimport random\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig\nfrom torch import nn\nimport sys\nimport gc\nfrom transformers import DataCollatorWithPadding\nfrom transformers import AdamW\nfrom accelerate import notebook_launcher\nfrom sklearn.model_selection import train_test_split\nfrom accelerate import DistributedDataParallelKwargs\nimport time\nimport re\nfrom transformers import get_cosine_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T23:12:36.477919Z","iopub.execute_input":"2023-11-30T23:12:36.478665Z","iopub.status.idle":"2023-11-30T23:12:52.447744Z","shell.execute_reply.started":"2023-11-30T23:12:36.478625Z","shell.execute_reply":"2023-11-30T23:12:52.446811Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Uncomment to enable Fully Sharded Data Parallel\n# os.environ[\"ACCELERATE_USE_FSDP\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:52.448822Z","iopub.execute_input":"2023-11-30T23:12:52.449320Z","iopub.status.idle":"2023-11-30T23:12:52.453491Z","shell.execute_reply.started":"2023-11-30T23:12:52.449293Z","shell.execute_reply":"2023-11-30T23:12:52.452462Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# From this Gist: https://gist.github.com/ihoromi4/b681a9088f348942b01711f251e5f964\ndef seed_everything(seed: int):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:52.456022Z","iopub.execute_input":"2023-11-30T23:12:52.456669Z","iopub.status.idle":"2023-11-30T23:12:52.470245Z","shell.execute_reply.started":"2023-11-30T23:12:52.456633Z","shell.execute_reply":"2023-11-30T23:12:52.469551Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def dict_from_class(cls):\n    return dict((key, value) for (key, value) in cls.__dict__.items() if not \"__\" in key )","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:52.471309Z","iopub.execute_input":"2023-11-30T23:12:52.471613Z","iopub.status.idle":"2023-11-30T23:12:52.481806Z","shell.execute_reply.started":"2023-11-30T23:12:52.471584Z","shell.execute_reply":"2023-11-30T23:12:52.481052Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class config:\n    # General Configuration\n    seed = 42\n    base_path = \"/kaggle/input/my-dear-watson-backtranslated-dataset\"\n    mode = \"maximize\"\n    device_type = \"gpus\"\n    \n    # WandB Configuration\n    name = \"Multilingual Models\"\n#     model_name = \"facebook/xlm-roberta-xl\"\n#     model_name = \"bert-base-multilingual-cased\"\n    model_name = \"xlm-roberta-large\"\n    metric_name = \"accuracy\"\n\n    # Training Hyperparameters\n    lr = 1e-4\n    epochs = 40\n    patience = 8\n    grad_accum = 4\n    grad_norm = 1.0           # Gradient Clipping\n    optimizer = \"AdamW\"\n    scheduler = \"Cosine\"\n    weight_decay = 0.3\n    pearson_weight = 0.0      # Percent of weight to put onto Pearson Correlation (Do not use due to NAN losses)\n    warmup = 0.1\n    mean_max_sampling = False # Whether or not to use mean-max sampling on the final BERT layer (Don't use due to instability)\n    \n    # Data Configuration\n    truncation = True\n    padding = True\n    test_size = 0.2\n    back_translate = 0.5      # Percent of time to back translate\n    upsample = False          # Whether or not to upsample (Don't turn this on as the train distribution will vary from test.)\n    \n    # LoRA hyperparameters\n    r = 8\n    lora_alpha = 16\n    lora_dropout = 0.0        # Dropout on LoRA Layers (Do not use as transformer already has dropout on by default)\n    bias = \"all\"\n        \nconfig.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\nconfig.checkpoint = f\"/kaggle/working/{config.model_name}.pt\"","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:52.482886Z","iopub.execute_input":"2023-11-30T23:12:52.483143Z","iopub.status.idle":"2023-11-30T23:12:56.068665Z","shell.execute_reply.started":"2023-11-30T23:12:52.483121Z","shell.execute_reply":"2023-11-30T23:12:56.067736Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c008cd7654447f8ff63ca1cde8cef3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcc54bd71bdb4bd086591f29a2dbb0e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5271c5755493466dbe570ab1990c9239"}},"metadata":{}}]},{"cell_type":"code","source":"if config.device_type == \"gpu\":\n    config.batch_size = 8\nelif config.device_type == \"gpus\":\n    config.batch_size = 8\nelif config.device_type == \"tpu\":\n    # Batch of 128 for each TPU core\n    config.batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:56.069772Z","iopub.execute_input":"2023-11-30T23:12:56.070081Z","iopub.status.idle":"2023-11-30T23:12:56.075110Z","shell.execute_reply.started":"2023-11-30T23:12:56.070055Z","shell.execute_reply":"2023-11-30T23:12:56.074055Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Signing into WandB\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\n!wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:56.076279Z","iopub.execute_input":"2023-11-30T23:12:56.076598Z","iopub.status.idle":"2023-11-30T23:12:59.822385Z","shell.execute_reply.started":"2023-11-30T23:12:56.076573Z","shell.execute_reply":"2023-11-30T23:12:59.821406Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.1) Trackers","metadata":{}},{"cell_type":"code","source":"class LossTracker:\n    def __init__(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.823769Z","iopub.execute_input":"2023-11-30T23:12:59.824081Z","iopub.status.idle":"2023-11-30T23:12:59.830991Z","shell.execute_reply.started":"2023-11-30T23:12:59.824053Z","shell.execute_reply":"2023-11-30T23:12:59.830036Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class AccuracyTracker():\n    def __init__(self):\n        self.correct_predictions = 0.0\n        self.total_predictions = 0.0\n        \n    def update(self, y_hat, y):\n        preds = y_hat.detach().cpu().numpy()\n        labels = y.detach().cpu().numpy()\n        \n        n = len(preds)\n        self.correct_predictions += (preds == labels).sum()        \n        self.total_predictions += n\n    \n    def score(self):\n        return self.correct_predictions / self.total_predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.834617Z","iopub.execute_input":"2023-11-30T23:12:59.834885Z","iopub.status.idle":"2023-11-30T23:12:59.847347Z","shell.execute_reply.started":"2023-11-30T23:12:59.834862Z","shell.execute_reply":"2023-11-30T23:12:59.846702Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class ModelTracker():\n    def __init__(self, model, optimizer, scheduler, accelerator):\n        self.missed = 0\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.metric = float(\"-inf\") if config.mode == \"maximize\" else float(\"inf\")\n        self.accelerator = accelerator\n        \n    def save_helper(self, epoch):\n        self.accelerator.save({\n                    \"epoch\": epoch, \n                    \"model_state_dict\": self.accelerator.unwrap_model(self.model).state_dict(), \n                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n                    \"scheduler\": self.scheduler.state_dict()\n                }, config.checkpoint)\n\n        self.accelerator.print(f\"Saved to model to {config.checkpoint}!\")\n        \n    def save_model(self, epoch):\n        self.save_helper(epoch)\n        \n\n    def update(self, value, epoch):\n        if config.mode == \"maximize\":\n            if value >= self.metric:\n                self.accelerator.print(f\"Validation {config.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.metric = value\n                self.save_model(epoch)    \n                self.missed = 0\n\n            else:\n                self.accelerator.print(f\"Validation {config.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.accelerator.print(f\"Model did not improve on epoch {epoch}\")\n                self.missed += 1\n        else:\n            if value <= self.metric:\n                self.accelerator.print(f\"Validation {config.metric_name} fell from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.metric = value\n                self.save_model(epoch) \n                self.missed = 0\n\n            else:\n                self.accelerator.print(f\"Validation {config.metric_name} rose from {self.metric:.4f} to {value:.4f} on epoch {epoch}\")\n                self.accelerator.print(f\"Model did not improve on epoch {epoch}\")\n                self.missed += 1\n        \n    def check_improvement(self):\n        return self.missed < config.patience","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.848538Z","iopub.execute_input":"2023-11-30T23:12:59.848806Z","iopub.status.idle":"2023-11-30T23:12:59.863088Z","shell.execute_reply.started":"2023-11-30T23:12:59.848783Z","shell.execute_reply":"2023-11-30T23:12:59.862151Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 2) Data Loading","metadata":{}},{"cell_type":"markdown","source":"# 2.1) Data Loading","metadata":{}},{"cell_type":"code","source":"class TrainData(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        selection = self.df.iloc[index]\n    \n        # Back Translation Code\n        premise = selection[\"bt_premise\"] if np.random.uniform() <= config.back_translate else selection[\"premise\"]\n        hypothesis = selection[\"bt_hypothesis\"] if np.random.uniform() <= config.back_translate else selection[\"hypothesis\"]\n        \n        return premise, hypothesis, selection[\"label\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.864270Z","iopub.execute_input":"2023-11-30T23:12:59.864631Z","iopub.status.idle":"2023-11-30T23:12:59.877183Z","shell.execute_reply.started":"2023-11-30T23:12:59.864601Z","shell.execute_reply":"2023-11-30T23:12:59.876502Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class TestData(Dataset):\n    def __init__(self, df):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        selection = self.df.iloc[index]\n        return selection[\"premise\"], selection[\"hypothesis\"], selection[\"label\"], selection[\"language\"]\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.878189Z","iopub.execute_input":"2023-11-30T23:12:59.878423Z","iopub.status.idle":"2023-11-30T23:12:59.888255Z","shell.execute_reply.started":"2023-11-30T23:12:59.878402Z","shell.execute_reply":"2023-11-30T23:12:59.887415Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Turns each batch of data into tensors\ndef train_collate_dynamic_padding(batch):\n    batch = np.array(batch, dtype = \"object\")\n    text_input = batch[:, 0:2].tolist()\n    labels = batch[:, 2].astype(int)\n    \n    tokens = config.tokenizer(text_input, padding=config.padding, truncation = config.truncation, return_tensors=\"pt\")\n    return tokens, torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.889273Z","iopub.execute_input":"2023-11-30T23:12:59.889499Z","iopub.status.idle":"2023-11-30T23:12:59.898675Z","shell.execute_reply.started":"2023-11-30T23:12:59.889479Z","shell.execute_reply":"2023-11-30T23:12:59.897981Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Turns each batch of data into tensors\ndef test_collate_dynamic_padding(batch):\n    batch = np.array(batch, dtype = \"object\")\n    text_input = batch[:, 0:2].tolist()\n    labels = batch[:, 2].astype(int)\n    languages = batch[:, 3]\n    \n    tokens = config.tokenizer(text_input, padding=config.padding, truncation = config.truncation, return_tensors=\"pt\")\n    return tokens, torch.tensor(labels), languages","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.899748Z","iopub.execute_input":"2023-11-30T23:12:59.900027Z","iopub.status.idle":"2023-11-30T23:12:59.912541Z","shell.execute_reply.started":"2023-11-30T23:12:59.900004Z","shell.execute_reply":"2023-11-30T23:12:59.911717Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# 3) Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, train_len):\n        super(Model, self).__init__()\n        self.train_len = train_len\n        self.base_model = AutoModel.from_pretrained(config.model_name)\n        if config.mean_max_sampling:\n            self.fc = nn.Linear(2 * self.base_model.config.hidden_size, 3)\n        else:\n            self.fc = nn.Linear(self.base_model.config.hidden_size, 3)\n    \n    def feature(self, inputs):\n        features = self.base_model(**inputs)[\"last_hidden_state\"]\n        # Taking the mean and max of all last hidden state tokens\n        if config.mean_max_sampling:\n            mean_pooling_embeddings = torch.mean(features, 1)\n            _, max_pooling_embeddings = torch.max(features, 1)\n            mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n\n            return mean_max_embeddings\n        else:\n            return features[:, 0, :]\n    \n    def forward(self, inputs):\n        features = self.feature(inputs)\n        \n        return self.fc(features)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.913709Z","iopub.execute_input":"2023-11-30T23:12:59.914347Z","iopub.status.idle":"2023-11-30T23:12:59.922829Z","shell.execute_reply.started":"2023-11-30T23:12:59.914322Z","shell.execute_reply":"2023-11-30T23:12:59.921984Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 4) Training Loop","metadata":{}},{"cell_type":"markdown","source":"## 4.1) Data Preparation","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(f\"{config.base_path}/train.csv\")\ntrain, test = train_test_split(train, test_size = config.test_size, stratify = train[\"lang_abv\"], random_state = config.seed)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:12:59.923903Z","iopub.execute_input":"2023-11-30T23:12:59.924506Z","iopub.status.idle":"2023-11-30T23:13:00.131386Z","shell.execute_reply.started":"2023-11-30T23:12:59.924475Z","shell.execute_reply":"2023-11-30T23:13:00.130416Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"}]},{"cell_type":"code","source":"# Validation Data and Test Data are both the same in this case!\n# They are distinguished for logging purposes!\ntrain_data, val_data, test_data = TrainData(train), TrainData(test), TestData(test)\n\nif config.upsample:\n# Getting sample weights for balancing data\n    weights = (1 / train.language.value_counts()).to_dict()\n    train[\"weight\"] = train.apply(lambda row: weights[row.language], axis = 1)\n    sample_weights = list(train[\"weight\"])\n\n    train_sampler = WeightedRandomSampler(sample_weights, len(train_data))\n\n    train_data_loader = DataLoader(train_data, collate_fn = train_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count(), sampler = train_sampler)\n    \nelse:\n    train_data_loader = DataLoader(train_data, collate_fn = train_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count(), shuffle = True)\n\n\nval_data_loader = DataLoader(test_data, collate_fn = train_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count())\ntest_data_loader = DataLoader(test_data, collate_fn = test_collate_dynamic_padding, batch_size = config.batch_size, pin_memory = True, num_workers = os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.132793Z","iopub.execute_input":"2023-11-30T23:13:00.133413Z","iopub.status.idle":"2023-11-30T23:13:00.142388Z","shell.execute_reply.started":"2023-11-30T23:13:00.133376Z","shell.execute_reply":"2023-11-30T23:13:00.141458Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 4.2) Training Functions","metadata":{}},{"cell_type":"code","source":"def generateConfusionMatrices(val_preds):\n    for lang in val_preds.langs.unique():\n        filtered_df = val_preds.loc[val_preds.langs == lang]\n        y = list(filtered_df.y.astype(int))\n        y_hat = list(filtered_df.y_hat.astype(int))\n        \n        wandb.log({f\"{lang} Confusion Matrix\": wandb.plot.confusion_matrix(y_true=y, preds=y_hat, class_names=[\"entailment\", \"contradiction\", \"neutral\"], title = f\"{lang} Confusion Matrix\", )})","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.143586Z","iopub.execute_input":"2023-11-30T23:13:00.143960Z","iopub.status.idle":"2023-11-30T23:13:00.157075Z","shell.execute_reply.started":"2023-11-30T23:13:00.143929Z","shell.execute_reply":"2023-11-30T23:13:00.156283Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, accelerator):\n    model.train()\n    model.to(config.device)\n    \n    loss_tracker = LossTracker()\n    accuracy_tracker = AccuracyTracker()\n\n    progress_bar = tqdm(train_loader, desc = f\"Training Loop Epoch: {epoch}\")\n    \n    average_acc = None\n    \n    for batch_idx, batch in enumerate(progress_bar):\n        with accelerator.accumulate(model):\n            inputs, labels = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(config.device)\n\n            labels = labels.to(config.device)\n            batch_size = labels.size(0)\n\n            logits = model(inputs)\n            # PyTorch CrossEntropy uses the unnormalized logits\n            train_loss = criterion(logits, labels)\n            scaled_loss = train_loss / config.grad_accum\n\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n\n            accuracy_tracker.update(y_hat, labels)\n\n            loss_tracker.update(train_loss.item(), batch_size)\n\n            accelerator.backward(scaled_loss)\n\n            if ((batch_idx + 1) % config.grad_accum == 0) or (batch_idx + 1 == len(train_loader)):\n\n                # Clip gradients once all of them are synced to main process\n                if accelerator.sync_gradients:\n                    accelerator.clip_grad_norm_(model.parameters(), config.grad_norm)\n                    \n                optimizer.step()\n\n                optimizer.zero_grad()\n\n                if not scheduler is None:\n                    scheduler.step()\n                    for i, lr in enumerate(scheduler.get_last_lr()):\n                        accelerator.log({f\"Layer {i} Learning Rate\": lr})\n                        \n                avg_accuracy = accuracy_tracker.score()\n                avg_loss = loss_tracker.avg\n                step_loss = loss_tracker.val\n                learning_rate = scheduler.get_last_lr()[0]\n\n                text = f\"Epoch: {epoch} | Average Training Accuracy: {avg_accuracy:.4f} | Average Training Loss: {avg_loss:.4f} | Step Training Loss: {step_loss:.4f} | Learning Rate: {learning_rate:.4f}\"\n                progress_bar.set_postfix_str(text)\n                progress_bar.refresh()\n\n                accelerator.log({f\"Step Training Loss\": step_loss})\n                \n\n    epoch_loss = loss_tracker.avg\n    epoch_accuracy = accuracy_tracker.score()\n\n    accelerator.log({f\"Training Loss Epoch\": epoch_loss})\n    accelerator.log({f\"Training Accuracy Epoch\": epoch_accuracy})\n    accelerator.print(f\"Training Loss: {epoch_loss} | Training Accuracy: {epoch_accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.158195Z","iopub.execute_input":"2023-11-30T23:13:00.158591Z","iopub.status.idle":"2023-11-30T23:13:00.172655Z","shell.execute_reply.started":"2023-11-30T23:13:00.158560Z","shell.execute_reply":"2023-11-30T23:13:00.171847Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def valid_fn(val_loader, model, criterion, epoch, accelerator):\n    with torch.no_grad():\n        model.eval()\n        model.to(config.device)\n\n        loss_tracker = LossTracker()\n        accuracy_tracker = AccuracyTracker()\n\n        progress_bar = tqdm(val_loader, desc = f\"Validation Loop Epoch: {epoch}\")\n\n        for batch_idx, batch in enumerate(progress_bar):\n\n            inputs, labels = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(config.device)\n\n            labels = labels.to(config.device)\n            batch_size = labels.size(0)\n\n            logits = accelerator.unwrap_model(model)(inputs)\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n\n            val_loss = criterion(logits, labels)\n\n            accuracy_tracker.update(y_hat, labels)\n            loss_tracker.update(val_loss.item(), batch_size)\n\n            avg_val_loss = loss_tracker.avg\n            avg_val_acc = accuracy_tracker.score()\n\n            progress_bar.set_postfix_str(f\"Epoch: {epoch} | Average Validation Accuracy {avg_val_acc:.4f}| Average Validation Loss: {avg_val_loss:.4f}\")\n            progress_bar.refresh()\n\n\n        epoch_loss = loss_tracker.avg\n        epoch_accuracy = accuracy_tracker.score()\n\n        accelerator.log({f\"Validation Loss Epoch\": epoch_loss})\n        accelerator.log({f\"Validation Accuracy Epoch\": epoch_accuracy})\n        accelerator.print(f\"Validation Loss: {epoch_loss} | Validation Accuracy: {epoch_accuracy}\")\n    \n    return epoch_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.173614Z","iopub.execute_input":"2023-11-30T23:13:00.173869Z","iopub.status.idle":"2023-11-30T23:13:00.188529Z","shell.execute_reply.started":"2023-11-30T23:13:00.173847Z","shell.execute_reply":"2023-11-30T23:13:00.187665Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def test_fn(test_loader, model, checkpoint, accelerator):\n    with torch.no_grad():\n        model.to(accelerator.device)\n        model.eval()\n\n        accuracy_tracker = AccuracyTracker()\n\n        preds = []\n        actual = []\n        langs = []\n\n        progress_bar = tqdm(test_loader, desc = f\"Test Loop\")\n        for batch_idx, batch in enumerate(progress_bar):\n\n            inputs, labels, languages = batch\n\n            for key, value in inputs.items():\n                inputs[key] = value.to(accelerator.device)\n\n            labels = labels.to(acclerator.device)\n            batch_size = labels.size(0)\n\n            logits = model(inputs)\n            y_hat = torch.nn.functional.softmax(logits, dim = 1)\n            y_hat = y_hat.argmax(dim = 1)\n            accuracy_tracker.update(y_hat, labels)\n\n            preds.extend(y_hat.detach().cpu().numpy())\n            actual.extend(labels.detach().cpu().numpy())\n            langs.extend(languages)\n\n\n            avg_val_acc = accuracy_tracker.score()\n\n            progress_bar.set_postfix_str(f\"Average Test Accuracy {avg_val_acc}\")\n            progress_bar.refresh()\n\n        test_accuracy = accuracy_tracker.score()\n\n        wandb.log({f\"Final Test Accuracy\": test_accuracy})\n        accelerator.print(f\"Test Accuracy: {test_accuracy}\")\n\n        test_preds = pd.DataFrame(np.array([preds, actual, langs]).T, columns = [\"y_hat\", \"y\", \"langs\"])\n        test_preds.to_csv(\"Test Predictions.csv\")\n        \n        # I need to run this because accelerator's API doesn't expose anything to directly save a csv.\n        wandb.save(f\"/kaggle/working/Test Predictions.csv\")\n        accelerator.print(\"Saved Test Predictions to /kaggle/working/Test Predictions.csv\")\n\n        generateConfusionMatrices(test_preds)\n\n        return test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.189837Z","iopub.execute_input":"2023-11-30T23:13:00.190205Z","iopub.status.idle":"2023-11-30T23:13:00.203978Z","shell.execute_reply.started":"2023-11-30T23:13:00.190147Z","shell.execute_reply":"2023-11-30T23:13:00.203189Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def getCustomLoss():\n    def customLoss(output, target):\n        ce = nn.CrossEntropyLoss()\n        x = output.argmax(dim = 1).to(dtype = float)\n        y = target.to(dtype = float)\n\n        vx = x - torch.mean(x)\n        vy = y - torch.mean(y)\n\n        pearsonCost = 1.0 - torch.sum(vx * vy) / (torch.norm(vx) * torch.norm(vy) + 1e-14)\n        ceCost = ce(output, target)\n\n        return ceCost + pearsonCost * config.pearson_weight\n    return customLoss","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.204994Z","iopub.execute_input":"2023-11-30T23:13:00.205251Z","iopub.status.idle":"2023-11-30T23:13:00.219004Z","shell.execute_reply.started":"2023-11-30T23:13:00.205229Z","shell.execute_reply":"2023-11-30T23:13:00.218179Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## 4.3) Model Loading","metadata":{}},{"cell_type":"code","source":"# model = torch.compile(Model(len(train_data_loader)))\nunwrapped_model = Model(len(train_data_loader))\n# model = Model(len(train_data_loader))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:00.219984Z","iopub.execute_input":"2023-11-30T23:13:00.220249Z","iopub.status.idle":"2023-11-30T23:13:11.705717Z","shell.execute_reply.started":"2023-11-30T23:13:00.220226Z","shell.execute_reply":"2023-11-30T23:13:11.704900Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"004019afc38246ba9729a9c9ad999ab5"}},"metadata":{}}]},{"cell_type":"code","source":"model_modules = str(unwrapped_model.modules)\npattern = r'\\((\\w+)\\): Linear'\nlinear_layer_names = re.findall(pattern, model_modules)\n\nnames = []\n# Print the names of the Linear layers\nfor name in linear_layer_names:\n    names.append(name)\ntarget_modules = list(set(names))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:11.706805Z","iopub.execute_input":"2023-11-30T23:13:11.707175Z","iopub.status.idle":"2023-11-30T23:13:11.715014Z","shell.execute_reply.started":"2023-11-30T23:13:11.707149Z","shell.execute_reply":"2023-11-30T23:13:11.714220Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(target_modules)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:11.716220Z","iopub.execute_input":"2023-11-30T23:13:11.716730Z","iopub.status.idle":"2023-11-30T23:13:11.726259Z","shell.execute_reply.started":"2023-11-30T23:13:11.716697Z","shell.execute_reply":"2023-11-30T23:13:11.725367Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"['query', 'key', 'value', 'dense', 'fc']\n","output_type":"stream"}]},{"cell_type":"code","source":"lora_config = LoraConfig(r = config.r, lora_alpha=config.lora_alpha, bias = config.bias, lora_dropout = config.lora_dropout, target_modules=target_modules)\nmodel = get_peft_model(unwrapped_model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:11.727272Z","iopub.execute_input":"2023-11-30T23:13:11.727548Z","iopub.status.idle":"2023-11-30T23:13:11.930263Z","shell.execute_reply.started":"2023-11-30T23:13:11.727501Z","shell.execute_reply":"2023-11-30T23:13:11.929190Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## 4.4) Train Loop","metadata":{}},{"cell_type":"code","source":"def train_loop(model):\n    seed_everything(config.seed)\n    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n    if config.device_type == \"gpu\" or config.device_type == \"gpus\":\n        accelerator = Accelerator(mixed_precision = \"fp16\", gradient_accumulation_steps = config.grad_accum, log_with = \"wandb\", kwargs_handlers=[ddp_kwargs])\n        config.device = accelerator.device\n    elif config.device_type == \"tpu\":\n        accelerator = Accelerator(mixed_precision = \"bf16\", gradient_accumulation_steps = config.grad_accum, log_with = \"wandb\", kwargs_handlers=[ddp_kwargs])\n        config.device = accelerator.device\n\n    accelerator.init_trackers(\n        \"My Dear Watson\",\n        config=dict_from_class(config),\n        init_kwargs={\n            \"wandb\": {\n                \"group\": config.name,\n                \"reinit\": False,\n                \"job_type\": config.model_name,\n                \"name\": f\"Seed {config.seed}\",\n                \"entity\": \"uw-kaggle\",\n            }\n        },\n    )\n    ######################################################################\n    criterion = getCustomLoss()\n    optimizer = AdamW(model.parameters(), weight_decay = config.weight_decay, lr = config.lr, correct_bias = True)\n\n    num_training_steps = model.train_len * config.epochs // config.grad_accum\n\n    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps = num_training_steps * config.warmup, num_training_steps = num_training_steps)\n    model, optimizer, train_loader, val_loader, scheduler = accelerator.prepare(model, optimizer, train_data_loader, val_data_loader, scheduler)\n    ######################################################################\n    tracker = ModelTracker(model, optimizer, scheduler, accelerator)\n    \n    for epoch in range(config.epochs):\n\n        train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, accelerator)\n\n        val_accuracy = valid_fn(val_loader, model, criterion, epoch, accelerator)\n\n        accelerator.wait_for_everyone()\n        tracker.update(val_accuracy, epoch)\n\n        if not tracker.check_improvement():\n            print(f\"Stopping the model at epoch {epoch} since the model did not improve!\")\n            break\n    \n    accelerator.wait_for_everyone()\n\n    gc.collect()\n\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:11.938628Z","iopub.execute_input":"2023-11-30T23:13:11.939326Z","iopub.status.idle":"2023-11-30T23:13:11.952786Z","shell.execute_reply.started":"2023-11-30T23:13:11.939285Z","shell.execute_reply":"2023-11-30T23:13:11.951720Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"if config.device_type == \"tpu\":\n    # Ignore print message that says it's running on 8 GPUs\n    notebook_launcher(train_loop, (model,), num_processes = 8)\n    \nelif config.device_type == \"gpus\":\n    notebook_launcher(train_loop, (model,), num_processes = torch.cuda.device_count())\n    \nelse:\n    train_loop(model)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:13:11.954235Z","iopub.execute_input":"2023-11-30T23:13:11.954965Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Launching training on one GPU.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgoggins\u001b[0m (\u001b[33muw-kaggle\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231130_231315-yw86x3ip</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/uw-kaggle/My%20Dear%20Watson/runs/yw86x3ip' target=\"_blank\">Seed 42</a></strong> to <a href='https://wandb.ai/uw-kaggle/My%20Dear%20Watson' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/uw-kaggle/My%20Dear%20Watson' target=\"_blank\">https://wandb.ai/uw-kaggle/My%20Dear%20Watson</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/uw-kaggle/My%20Dear%20Watson/runs/yw86x3ip' target=\"_blank\">https://wandb.ai/uw-kaggle/My%20Dear%20Watson/runs/yw86x3ip</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nTraining Loop Epoch: 0:  18%|█▊        | 219/1212 [00:49<03:39,  4.53it/s, Epoch: 0 | Average Training Accuracy: 0.3559 | Average Training Loss: 1.1611 | Step Training Loss: 1.2702 | Learning Rate: 0.0000]","output_type":"stream"}]},{"cell_type":"code","source":"%debug","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5) Getting Test Predictions","metadata":{}},{"cell_type":"code","source":"accelerator = Accelerator(log_with = \"wandb\")\naccelerator.init_trackers(\n        \"My Dear Watson\",\n        config=dict_from_class(config),\n        init_kwargs={\n            \"wandb\": {\n                \"group\": config.name,\n                \"reinit\": False,\n                \"resume\": True,\n                \"job_type\": config.model_name,\n                \"name\": f\"Seed {config.seed}\",\n                \"entity\": \"uw-kaggle\",\n            }\n        },\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved = torch.load(config.checkpoint)\n# model = accelerator.unwrap_model(model)\nmodel.load_state_dict(saved[\"model_state_dict\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, test_loader = accelerator.prepare(model, test_data_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_fn(test_loader, model, config.checkpoint, accelerator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accelerator.end_training()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}